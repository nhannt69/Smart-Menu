{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\smart_menu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.contrib.concurrent import thread_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>COMBO 1</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>COMBO 2</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>COMBO 3</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU SOJU</td>\n",
       "      <td>SOJU</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001.jpeg</td>\n",
       "      <td>RƯỢU VODKA</td>\n",
       "      <td>VODKA</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ImageName VietnameseName EnglishName      Price\n",
       "0  001.jpeg        COMBO 1     COMBO 1     169000\n",
       "1  001.jpeg        COMBO 2     COMBO 2     169000\n",
       "2  001.jpeg        COMBO 3     COMBO 3     169000\n",
       "3  001.jpeg      RƯỢU SOJU        SOJU  NOT GIVEN\n",
       "4  001.jpeg     RƯỢU VODKA       VODKA  NOT GIVEN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data_sample/Data_Labeling.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>VietnameseName</th>\n",
       "      <th>EnglishName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15206</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>SÒ ĐIỆP NƯỚNG</td>\n",
       "      <td>GRILLED SCALLOP</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15207</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>KHÔ MỰC</td>\n",
       "      <td>DRIED SQUID</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ SƠN NƯỚNG</td>\n",
       "      <td>GRILLED CARDINAL FISH</td>\n",
       "      <td>NOT GIVEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ CHỈ VÀNG</td>\n",
       "      <td>YELLOWSTRIPE SCAD</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>850.jpeg</td>\n",
       "      <td>CÁ LAO NƯỚNG</td>\n",
       "      <td>GRILLED RED CORNETFISH</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ImageName VietnameseName             EnglishName      Price\n",
       "15206  850.jpeg  SÒ ĐIỆP NƯỚNG         GRILLED SCALLOP      10000\n",
       "15207  850.jpeg        KHÔ MỰC             DRIED SQUID  NOT GIVEN\n",
       "15208  850.jpeg   CÁ SƠN NƯỚNG   GRILLED CARDINAL FISH  NOT GIVEN\n",
       "15209  850.jpeg    CÁ CHỈ VÀNG       YELLOWSTRIPE SCAD      60000\n",
       "15210  850.jpeg  CÁ LAO NƯỚNG   GRILLED RED CORNETFISH      99000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get Vietnamese food names\n",
    "food_names = df['VietnameseName'].values\n",
    "type(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belgian', 'dark', 'ibu', 'phở', 'đùi', 'trứng', 'non', 'hải', 'sản', 'xuân']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean text, remove punification number and etc\n",
    "import re\n",
    "\n",
    "def clean_food_name(food_name):\n",
    "    #Remove quantity for example 500ML 1L 20KG ....\n",
    "    food_name = food_name.lower()\n",
    "    food_name = re.sub(r'\\d+\\w+', ' ', food_name)\n",
    "    #Remove purification and digits\n",
    "    food_name = re.sub(r\"[^\\w\\s]|\\d\", ' ', food_name)\n",
    "    #Remove size entites\n",
    "    token = r\"\\s+x{0,2}[xlms][\\.:-]?\\b|(nhỏ|vừa|lớn|bự|to|small|medium|big|large):?\"\n",
    "    food_name = re.sub(token, \" \", food_name)\n",
    "    #Remove specail token\n",
    "    food_name = re.sub(r\"_x\", ' ', food_name)\n",
    "    \n",
    "    food_name = food_name.strip().split()\n",
    "    return food_name\n",
    "    \n",
    "\n",
    "test = clean_food_name('BELGIAN DARK 8.1%/IBU 32 -    X 500ML (PHỞ ĐÙI + TRỨNG NON) X L M nhỏ vừa_x hải sản xuân')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['belgian dark', 'dark ibu', 'ibu phở', 'phở đùi', 'đùi trứng', 'trứng non', 'non hải', 'hải sản']\n"
     ]
    }
   ],
   "source": [
    "def get_big_gram(text, n=2, m=2):\n",
    "    words = clean_food_name(text)\n",
    "    big_grams = []\n",
    "    \n",
    "    for k in range(n,m+1):\n",
    "        for i in range(len(words)):\n",
    "            big_gram = ''\n",
    "            if i + k > len(words):\n",
    "                continue\n",
    "            \n",
    "            for j in range(k):\n",
    "                big_gram += words[i+j] + ' '\n",
    "                \n",
    "            big_grams.append(big_gram.strip())\n",
    "            \n",
    "    return big_grams\n",
    "\n",
    "print(get_big_gram('BELGIAN DARK 8.1%/IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON) hải sản'))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15211/15211 [00:00<00:00, 289708.28it/s]\n",
      "100%|██████████| 15211/15211 [00:00<00:00, 294910.94it/s]\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = thread_map(clean_food_name, food_names, max_workers=6)\n",
    "food_vocabulary_big_grams = thread_map(get_big_gram, food_names, max_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['combo', 'combo', 'combo', 'rượu', 'soju', 'rượu', 'vodka', 'tiger', 'lon', 'tiger']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary = [item for sublist in food_vocabulary for item in sublist]\n",
    "print(food_vocabulary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rượu soju', 'rượu vodka', 'tiger lon', 'tiger chai', 'tiger bạc', 'bạc chai', 'tiger bạc', 'bạc lon', 'bò húc', 'bia quy', 'quy nhơn', 'bia bivina', 'strong bow', 'rau muống', 'muống xào', 'xào tỏi', 'mồng tơi', 'tơi xào', 'xào tỏi', 'cải xào']\n"
     ]
    }
   ],
   "source": [
    "food_vocabulary_big_grams = [item for sublist in food_vocabulary_big_grams for item in sublist]\n",
    "print(food_vocabulary_big_grams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cá', 1513),\n",
       " ('trà', 1312),\n",
       " ('nướng', 1174),\n",
       " ('sữa', 1117),\n",
       " ('chiên', 1053),\n",
       " ('bò', 1014),\n",
       " ('xào', 823),\n",
       " ('gà', 779),\n",
       " ('tôm', 710),\n",
       " ('cơm', 620)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = Counter(food_vocabulary)\n",
    "corpus.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trà sữa', 472),\n",
       " ('hải sản', 374),\n",
       " ('phô mai', 322),\n",
       " ('trân châu', 252),\n",
       " ('cơm chiên', 245),\n",
       " ('cá hồi', 240),\n",
       " ('sữa chua', 212),\n",
       " ('chiên mắm', 177),\n",
       " ('thập cẩm', 166),\n",
       " ('muối ớt', 161)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_big_grams = Counter(food_vocabulary_big_grams)\n",
    "corpus_big_grams.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus\n",
    "with open('food_vocabulary.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus.most_common():\n",
    "        if count > 1:\n",
    "            save_format = f\"{food}${count}\\n\"\n",
    "            f.write(save_format)\n",
    "\n",
    "with open('food_vocabulary_big_grams.txt', 'w', encoding='utf-8') as f:\n",
    "    for food, count in corpus_big_grams.most_common():\n",
    "        if count > 1:\n",
    "            save_format = f\"{food}${count}\\n\"\n",
    "            f.write(save_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell correct with symspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symspellpy\n",
    "import random\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BELGIAN DARK 8.1%IB32 - 50L (PHỞ ÙI+ TRỨN NON)'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_delete(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = random.randint(0, len(text_aggumented)-1)\n",
    "        del text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_replace(text, percent = 0.2):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "\n",
    "        char = random.choice(string.ascii_uppercase)\n",
    "        text_aggumented[k] = char\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def random_swap(text, percent = 0.1):\n",
    "    n = int(percent*len(text))+1\n",
    "    text_aggumented = list(text)\n",
    "    \n",
    "    for i in range(n):\n",
    "        k = -1\n",
    "        while k == -1 or text[k] == ' ':\n",
    "            k = random.randint(0, len(text)-1)\n",
    "        h = k\n",
    "        while h == k or text[h] == ' ':\n",
    "            h = random.randint(0, len(text)-1)\n",
    "        text_aggumented[k], text_aggumented[h] = text_aggumented[h], text_aggumented[k]\n",
    "        \n",
    "    return \"\".join(text_aggumented)\n",
    "\n",
    "def lower(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def random_text_aggument(text):\n",
    "    k = random.randint(0, 2)\n",
    "    random_agg = {0: random_delete, 1:random_replace, 2:random_swap}\n",
    "    return random_agg[k](text, percent=0.125)\n",
    "    \n",
    "random_text_aggument('BELGIAN DARK 8.1%IBU 32 - 500ML (PHỞ ĐÙI + TRỨNG NON)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 250047.93it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 249869.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cá kèo nấu rau răm', 'bánh canh', 'pizza khoai tây size m', 'nem chua chiên hà nội', 'trà lipton', 'lẩu gà lá giang', 'đậu bắp luộc']\n",
      "['rr ăèo nấu cau ákm', 'bánh ch', 'pizza kRoai QAy size m', 'nim chue chaêộ hà nni', 'trà MPpton', 'lẩC gà lá gianG', 'đậu bắp lộ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_CASE = random.choices(food_names, k = 500)\n",
    "TEST_CASE = thread_map(lower, TEST_CASE, max_workers=6)\n",
    "TEST_CASE_WRONG = thread_map(random_text_aggument, TEST_CASE, max_workers=6)\n",
    "\n",
    "print(TEST_CASE[:7])\n",
    "print(TEST_CASE_WRONG[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cer(pred, true):\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "def wer(pred, true):\n",
    "    pred = pred.split()\n",
    "    true = true.split()\n",
    "    n = len(true)\n",
    "    wrong = 0\n",
    "    for c1, c2 in zip(pred, true):\n",
    "        if c1 != c2:\n",
    "            wrong += 1\n",
    "    \n",
    "    return (n - wrong)/n\n",
    "\n",
    "print(cer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\"))\n",
    "wer(\"tomorrow now today and tomorrow\", \"tomorrow now today and tomoraow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cá', 1513), ('trà', 1312), ('nướng', 1174), ('sữa', 1117), ('chiên', 1053)]\n",
      "[('trà sữa', 472), ('hải sản', 374), ('phô mai', 322), ('trân châu', 252), ('cơm chiên', 245)]\n"
     ]
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "EDIT_DISTANCE = 3\n",
    "\n",
    "spell_check = SymSpell(max_dictionary_edit_distance=EDIT_DISTANCE)\n",
    "spell_check.load_dictionary('food_vocabulary.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "spell_check.load_bigram_dictionary('food_vocabulary_big_grams.txt', 0, 1, \n",
    "                                    encoding='utf-8', separator='$')\n",
    "\n",
    "print(list(islice(spell_check.words.items(), 5)))\n",
    "print(list(islice(spell_check.bigrams.items(), 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spell(text):\n",
    "    import re \n",
    "    \n",
    "    text = re.sub(r'[.\\?#@+,<>%~`!$^&\\(\\):;\\\\\\/]', r' \\g<0> ', text)\n",
    "    \n",
    "    suggestion = spell_check.lookup_compound(text, max_edit_distance=EDIT_DISTANCE,\n",
    "                                             ignore_non_words=True, ignore_term_with_digits=True)\n",
    "    \n",
    "    return suggestion[0]._term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      "['cá kèo nấu rau răm', 'bánh canh', 'pizza khoai tây size m', 'nem chua chiên hà nội', 'trà lipton', 'lẩu gà lá giang', 'đậu bắp luộc']\n",
      "['rr ăèo nấu cau ákm', 'bánh ch', 'pizza kRoai QAy size m', 'nim chue chaêộ hà nni', 'trà MPpton', 'lẩC gà lá gianG', 'đậu bắp lộ']\n",
      "['ri xèo nấu cau tôm', 'bánh cá', 'pizza khoai cay size m', 'nấm chua chiên hà nội', 'trà m non', 'lẩu gà lá giang', 'đậu bắp lá']\n",
      "Metric: WER: 0.689 CER: 0.731\n",
      "CPU times: total: 469 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_result = []\n",
    "wer_result = []\n",
    "cer_result = []\n",
    "N = 7\n",
    "for test_case, val in zip(TEST_CASE_WRONG, TEST_CASE):\n",
    "    correct_text = correct_spell(test_case)\n",
    "    \n",
    "    test_result.append(correct_text)\n",
    "        \n",
    "        \n",
    "    wer_result.append(\n",
    "        wer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "    cer_result.append(\n",
    "        cer(correct_text, val)\n",
    "    )\n",
    "    \n",
    "\n",
    "print(\"Example: \")\n",
    "print(TEST_CASE[:N])\n",
    "print(TEST_CASE_WRONG[:N])\n",
    "print(test_result[:N])\n",
    "\n",
    "print(\"Metric:\", f\"WER: {np.mean(wer_result):.3f}\", f\"CER: {np.mean(cer_result):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('smart_menu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cca91d1f76e5abfdd07e2c17342a07bd112c752dc295866857041e010f5f929"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
